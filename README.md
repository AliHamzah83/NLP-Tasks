# Arabic RAG System ğŸ”
## Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ ÙˆØ§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ

A comprehensive Arabic Retrieval-Augmented Generation (RAG) system that combines document retrieval with Arabic text generation using state-of-the-art models.

## ğŸŒŸ Features

### Core Components
- **ğŸ“š Data Collection**: Configurable data directory with support for multiple file formats (TXT, JSON, CSV)
- **ğŸ”§ Text Preprocessing**: Arabic-specific preprocessing with noise removal, normalization, and tokenization using Farasa/CAMeL Tools
- **âœ‚ï¸ Chunking Strategies**: Fixed-size and sentence-based text splitting optimized for Arabic
- **ğŸ§  Embedding Model**: Multilingual sentence embeddings using `paraphrase-multilingual-mpnet-base-v2`
- **ğŸ—„ï¸ Vector Database**: ChromaDB integration for efficient similarity search
- **ğŸ¤– Language Model**: AraGPT2 for Arabic text generation
- **ğŸ“Š Evaluation System**: Comprehensive metrics for retrieval and generation quality
- **ğŸš€ Production Deployment**: FastAPI backend and Streamlit frontend

### Key Capabilities
- âœ… Arabic question answering with context retrieval
- âœ… Document management and knowledge base building
- âœ… Multi-strategy text chunking
- âœ… Real-time query processing
- âœ… Performance evaluation and metrics
- âœ… RESTful API with comprehensive endpoints
- âœ… Modern web interface with Arabic support
- âœ… Batch processing capabilities
- âœ… Export/import functionality

## ğŸ—ï¸ Architecture

```
Arabic RAG System
â”œâ”€â”€ Data Collection & Preprocessing
â”‚   â”œâ”€â”€ Multi-format file loading (TXT, JSON, CSV)
â”‚   â”œâ”€â”€ Arabic text normalization
â”‚   â”œâ”€â”€ Tokenization (Farasa/CAMeL Tools)
â”‚   â””â”€â”€ Noise removal and cleaning
â”œâ”€â”€ Text Chunking
â”‚   â”œâ”€â”€ Fixed-size chunking
â”‚   â”œâ”€â”€ Sentence-based chunking
â”‚   â””â”€â”€ Overlap management
â”œâ”€â”€ Embedding & Retrieval
â”‚   â”œâ”€â”€ Sentence Transformers (multilingual)
â”‚   â”œâ”€â”€ ChromaDB vector storage
â”‚   â””â”€â”€ Similarity search
â”œâ”€â”€ Generation
â”‚   â”œâ”€â”€ AraGPT2 integration
â”‚   â”œâ”€â”€ Context-aware generation
â”‚   â””â”€â”€ Confidence scoring
â”œâ”€â”€ Evaluation
â”‚   â”œâ”€â”€ Retrieval metrics (Precision, Recall, F1)
â”‚   â”œâ”€â”€ Generation quality metrics
â”‚   â””â”€â”€ Performance analysis
â””â”€â”€ Deployment
    â”œâ”€â”€ FastAPI backend
    â”œâ”€â”€ Streamlit frontend
    â””â”€â”€ Production-ready APIs
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended for better performance)
- 8GB+ RAM
- 10GB+ disk space for models and data

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd arabic-rag-system
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Download required NLTK data**
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

### Basic Usage

#### 1. Run the Demo
```bash
python demo.py
```

This will demonstrate all system capabilities including:
- Knowledge base building
- Arabic query processing
- Document management
- System evaluation

#### 2. Start the Backend API
```bash
cd backend
python main.py
```

The API will be available at `http://localhost:8000`
- API Documentation: `http://localhost:8000/docs`
- Alternative docs: `http://localhost:8000/redoc`

#### 3. Launch the Frontend
```bash
cd frontend
streamlit run streamlit_app.py
```

The web interface will be available at `http://localhost:8501`

## ğŸ“– Detailed Usage

### Python API

#### Initialize the RAG System
```python
from arabic_rag import ArabicRAGPipeline

# Initialize with default settings
rag = ArabicRAGPipeline()

# Or customize configuration
rag = ArabicRAGPipeline(
    data_dir="my_data",
    embedding_model_name="paraphrase-multilingual-mpnet-base-v2",
    llm_model_name="aubmindlab/aragpt2-base",
    chunking_strategy="sentence_based",
    chunk_size=512,
    chunk_overlap=50
)
```

#### Build Knowledge Base
```python
# Build from data directory
build_stats = rag.build_knowledge_base()

# Force rebuild
build_stats = rag.build_knowledge_base(force_rebuild=True)
```

#### Query the System
```python
# Basic query
result = rag.query("Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ")

# Advanced query with parameters
result = rag.query(
    question="ÙƒÙŠÙ ØªØ¹Ù…Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©ØŸ",
    top_k=5,
    max_contexts=3,
    similarity_threshold=0.5
)

print(f"Answer: {result['answer']}")
print(f"Confidence: {result['confidence']}")
print(f"Processing time: {result['processing_time']}s")
```

#### Add Documents
```python
# Add custom documents
documents = [
    {
        "text": "Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†Ø§...",
        "metadata": {"title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©", "author": "Ø§Ù„Ù…Ø¤Ù„Ù"}
    }
]

success = rag.add_documents(documents)
```

#### Evaluation
```python
from arabic_rag import ArabicRAGEvaluator

evaluator = ArabicRAGEvaluator(rag)

# Create test dataset
test_questions = [
    "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ",
    "ÙƒÙŠÙ ØªØ¹Ù…Ù„ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©ØŸ"
]

test_dataset = evaluator.create_test_dataset(test_questions)

# Run evaluation
metrics = evaluator.evaluate_end_to_end(test_dataset)

print(f"F1 Score: {metrics.f1_score}")
print(f"Answer Accuracy: {metrics.answer_accuracy}")
```

### REST API Endpoints

#### Health Check
```bash
curl http://localhost:8000/health
```

#### Query
```bash
curl -X POST "http://localhost:8000/query" \
     -H "Content-Type: application/json" \
     -d '{
       "question": "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ",
       "top_k": 5,
       "max_contexts": 3
     }'
```

#### Add Document
```bash
curl -X POST "http://localhost:8000/documents/add" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†Ø§...",
       "metadata": {"title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©"}
     }'
```

#### Build Knowledge Base
```bash
curl -X POST "http://localhost:8000/knowledge-base/build" \
     -H "Content-Type: application/json" \
     -d '{"force_rebuild": false}'
```

## âš™ï¸ Configuration

### System Configuration
```python
from arabic_rag import ArabicRAGPipeline

rag = ArabicRAGPipeline(
    # Data settings
    data_dir="data",                    # Data directory path
    db_path="chroma_db",               # Vector database path
    collection_name="arabic_documents", # Collection name
    
    # Model settings
    embedding_model_name="paraphrase-multilingual-mpnet-base-v2",
    llm_model_name="aubmindlab/aragpt2-base",
    
    # Chunking settings
    chunking_strategy="sentence_based", # or "fixed_size"
    chunk_size=512,                     # Characters per chunk
    chunk_overlap=50                    # Overlap between chunks
)
```

### Preprocessing Configuration
```python
from arabic_rag import PreprocessingConfig, ArabicTextPreprocessor

config = PreprocessingConfig(
    remove_diacritics=True,    # Remove Arabic diacritics
    normalize_alef=True,       # Normalize Alef variations
    normalize_teh_marbuta=True, # Normalize Teh Marbuta
    remove_punctuation=True,   # Remove punctuation
    remove_english=True,       # Remove English characters
    remove_numbers=False,      # Keep numbers
    remove_stopwords=True,     # Remove Arabic stopwords
    min_word_length=2,         # Minimum word length
    use_farasa=True,          # Use Farasa tokenizer
    use_camel=True            # Use CAMeL Tools
)

preprocessor = ArabicTextPreprocessor(config)
```

### Chunking Configuration
```python
from arabic_rag import ChunkingConfig, ArabicTextChunker

config = ChunkingConfig(
    chunk_size=512,           # Target chunk size
    chunk_overlap=50,         # Overlap between chunks
    min_chunk_size=100,       # Minimum chunk size
    max_chunk_size=1000,      # Maximum chunk size
    preserve_sentences=True,   # Preserve sentence boundaries
    strategy="sentence_based"  # Chunking strategy
)

chunker = ArabicTextChunker(config)
```

## ğŸ“Š Evaluation Metrics

The system provides comprehensive evaluation metrics:

### Retrieval Metrics
- **Precision**: Fraction of retrieved documents that are relevant
- **Recall**: Fraction of relevant documents that are retrieved
- **F1-Score**: Harmonic mean of precision and recall
- **MAP (Mean Average Precision)**: Average precision across queries
- **MRR (Mean Reciprocal Rank)**: Average reciprocal rank of first relevant document

### Generation Metrics
- **Answer Accuracy**: Exact match rate with reference answers
- **Answer Completeness**: Partial match rate based on word overlap
- **Semantic Similarity**: Cosine similarity between generated and reference answers
- **Confidence Score**: Model's confidence in generated answers

### Performance Metrics
- **Success Rate**: Percentage of successful query processing
- **Average Response Time**: Mean time to process queries
- **Throughput**: Queries processed per second

## ğŸ—‚ï¸ Data Formats

### Supported Input Formats

#### Text Files (.txt)
```
Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‡Ùˆ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¨Ø´Ø±ÙŠ ÙÙŠ Ø§Ù„Ø¢Ù„Ø§Øª.
Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ÙØ±Ø¹ Ù…Ù‡Ù… Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
```

#### JSON Files (.json)
```json
[
  {
    "text": "Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†Ø§...",
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©",
    "author": "Ø§Ù„Ù…Ø¤Ù„Ù",
    "category": "ØªÙ‚Ù†ÙŠØ©"
  }
]
```

#### CSV Files (.csv)
```csv
text,title,author,category
"Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø£ÙˆÙ„...","Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ÙˆÙ„","Ø§Ù„Ù…Ø¤Ù„Ù Ø§Ù„Ø£ÙˆÙ„","ØªÙ‚Ù†ÙŠØ©"
"Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠ...","Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø«Ø§Ù†ÙŠ","Ø§Ù„Ù…Ø¤Ù„Ù Ø§Ù„Ø«Ø§Ù†ÙŠ","Ø¹Ù„ÙˆÙ…"
```

## ğŸ”§ Advanced Features

### Custom Embedding Models
```python
# Use different embedding models
rag = ArabicRAGPipeline(
    embedding_model_name="sentence-transformers/all-MiniLM-L6-v2"
)
```

### Custom Language Models
```python
# Use different AraGPT2 variants
rag = ArabicRAGPipeline(
    llm_model_name="aubmindlab/aragpt2-medium"  # or aragpt2-large
)
```

### Batch Processing
```python
# Process multiple queries
questions = [
    "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ",
    "ÙƒÙŠÙ ØªØ¹Ù…Ù„ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©ØŸ",
    "Ù…Ø§ Ù‡ÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ØŸ"
]

results = rag.batch_query(questions)
```

### Export/Import
```python
# Export knowledge base
rag.export_knowledge_base("my_knowledge_base.json")

# Reset knowledge base
rag.reset_knowledge_base()
```

## ğŸ› Troubleshooting

### Common Issues

#### 1. CUDA Out of Memory
```python
# Use CPU instead of GPU
rag = ArabicRAGPipeline()
# Models will automatically fall back to CPU
```

#### 2. Slow Performance
```python
# Reduce chunk size and batch size
rag = ArabicRAGPipeline(
    chunk_size=256,  # Smaller chunks
    chunk_overlap=25
)
```

#### 3. Poor Arabic Text Quality
```python
# Adjust preprocessing settings
from arabic_rag import PreprocessingConfig

config = PreprocessingConfig(
    remove_diacritics=False,  # Keep diacritics
    normalize_alef=True,      # Normalize Alef
    remove_stopwords=False    # Keep stopwords
)
```

#### 4. Low Retrieval Accuracy
```python
# Adjust similarity threshold
result = rag.query(
    question="Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§",
    similarity_threshold=0.3  # Lower threshold
)
```

### Error Messages

- **"System not initialized"**: Run the initialization code first
- **"No documents found"**: Check data directory and file formats
- **"ChromaDB error"**: Ensure ChromaDB is properly installed
- **"Model loading failed"**: Check internet connection and disk space

## ğŸ“ˆ Performance Optimization

### Hardware Recommendations
- **CPU**: Multi-core processor (8+ cores recommended)
- **RAM**: 16GB+ for large knowledge bases
- **GPU**: NVIDIA GPU with 8GB+ VRAM for optimal performance
- **Storage**: SSD recommended for faster I/O

### Software Optimization
```python
# Use smaller models for faster inference
rag = ArabicRAGPipeline(
    embedding_model_name="sentence-transformers/all-MiniLM-L6-v2",
    llm_model_name="aubmindlab/aragpt2-base"  # Use base instead of large
)

# Optimize chunk size
rag = ArabicRAGPipeline(
    chunk_size=256,      # Smaller chunks for faster processing
    chunk_overlap=25     # Smaller overlap
)
```

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Run linting
flake8 arabic_rag/
black arabic_rag/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Hugging Face** for the Transformers library
- **ChromaDB** for vector database capabilities
- **Sentence Transformers** for embedding models
- **AubmindLab** for AraGPT2 models
- **CAMeL Tools** and **Farasa** for Arabic NLP

## ğŸ“ Support

For support and questions:
- ğŸ“§ Email: [your-email@domain.com]
- ğŸ’¬ GitHub Issues: [Create an issue](../../issues)
- ğŸ“– Documentation: [Wiki](../../wiki)

## ğŸ—ºï¸ Roadmap

### Upcoming Features
- [ ] Support for more Arabic dialects
- [ ] Integration with more embedding models
- [ ] Advanced evaluation metrics
- [ ] Multi-modal support (text + images)
- [ ] Real-time learning capabilities
- [ ] Enhanced web interface
- [ ] Mobile app support

### Version History
- **v1.0.0**: Initial release with core RAG functionality
- **v1.1.0**: Added evaluation system and metrics
- **v1.2.0**: Enhanced Arabic preprocessing
- **v1.3.0**: Added production deployment features

---

**Built with â¤ï¸ for the Arabic NLP community**

Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ ÙˆØ§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ - Ù…ØµÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ğŸ‡¸ğŸ‡¦